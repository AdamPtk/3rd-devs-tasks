<html>
    <head>
<title>AI_devs Ag3nts</title>
<link href="https://cdn.prod.website-files.com/667438c9537d1149a7ed7aa0/6674398649ca1a2a2aa11388_AI-devs_favicon.png" rel="shortcut icon" type="image/x-icon"/><link href="https://cdn.prod.website-files.com/667438c9537d1149a7ed7aa0/6674398b44eb03b6de79c05d_Ai-devs_webclip.png" rel="apple-touch-icon"/>
<script src="https://app.easycart.pl/login.js?type=block&id=prod_QL9DPzGDmkLYH8"></script>

<script>
    !window._EC_HASH_7f00389085f9b8a945e653716b42933a && (location.href = "https://app.easycart.pl/r/prod_QL9DPzGDmkLYH8");
</script>

<noscript>
    <meta http-equiv="refresh" content="0;url=https://app.easycart.pl/r/prod_QL9DPzGDmkLYH8">
</noscript>


<style>
@media (prefers-color-scheme: dark) {
  :root {
    --bg-color: #1a1a1a;
    --text-color: #ffffff;
    --link-color: #8ffa7d;
  }
}

@media (prefers-color-scheme: light) {
  :root {
    --bg-color: #ffffff;
    --text-color: #1a1a1a;
    --link-color: #0066cc;
  }
}

body {
  background-color: var(--bg-color);
  color: var(--text-color);
}

body a {
  color: var(--link-color);
}
    iframe, img {
        max-width: 100%;
    }
    iframe {
        max-height: 400px; margin: 15px;
    }
body { font-family: sans-serif; }
    body p {
        margin-bottom: 15px;
    }

    body a {
        display: inline;
    }
    body a:hover {
        text-decoration: underline;
    }

    body img {
        margin: 5px 0;
    }

    body h2 {
        font-weight: bold;
        font-size: 1.5rem;
        margin-bottom: 15px;
    }

    br {
        display: none;
    }

    body hr {
        margin: 15px 0;
    }
    
    body ul, ol {
        padding-left: 15px;
    }
    body li {
        list-style-type: initial;
    }
</style>
<script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="prose" style="max-width: 800px; margin: 25px auto;">
<img src="https://assets-v2.circle.so/7o7q1z71s3aautgyiizby713xw4x" />
<div><p>📎 <a href="https://cloud.overment.com/S04E03-1732688101.md" target="_blank" rel="noopener noreferrer"><strong>Pobierz treść tej lekcji w formacie markdown</strong></a></p><p>📎 <a href="https://cloud.overment.com/S04E03-en-1732688272.md" target="_blank" rel="noopener noreferrer"><strong>Pobierz treść tej lekcji w formacie markdown</strong></a><strong> (EN)</strong></p><blockquote><p>W tej lekcji pojawia się tylko jeden przykład <a href="https://github.com/i-am-alice/3rd-devs/tree/main/web" target="_blank" rel="noopener noreferrer"><strong>web</strong></a>, który stanowi połączenie przykładów omawianych we wcześniejszych lekcjach.</p></blockquote><p>Mamy już kilka gotowych elementów, które umożliwiają łączenie LLM z zewnętrznymi danymi w postaci plików przekazanych jako adresy URL lub ścieżki do plików zapisanych na dysku. Poza tym, omawialiśmy także przykład websearch, który pozwolił nam na proste połączenie modelu z Internetem.</p><p>Rzecz w tym, że źródła danych mogą mieć także inny charakter. Przykładem są informacje z otoczenia (lokalizacja, uruchomione aplikacje na telefonie, aktualna pogoda czy obecnie odtwarzana muzyka). Część z nich może być pobierana w czasie rzeczywistym, a inne będą aktualizowane cyklicznie i wczytywane tylko w razie potrzeby. Mówimy więc tutaj o sytuacji w których dane nie pochodzą od użytkownika, lecz są pobierane programistycznie, a nasz system ma prawo je wczytać w razie potrzeby.</p><p>Ostatnim przykładem danych są także te dostarczane przez użytkownika bądź innych agentów AI <strong>w trakcie interakcji</strong>. Chociażby podczas dłuższej rozmowy, wskazane jest budowanie kontekstu konwersacji, który nie jest w całości dostarczany do systemowego promptu.</p><p>W tym wszystkim brakuje jeszcze możliwości <strong>tworzenia treści</strong> oraz <strong>zapisywania plików</strong>. Tutaj także kilka przykładów widzieliśmy już w poprzednich tygodniach AI_devs, ale teraz połączymy je ze sobą w formę narzędzi, którymi będzie posługiwać się model.</p><h2>Przegląd logiki</h2><p>W tej lekcji będziemy omawiać przykład web, który łączy ze sobą logikę przykładów takich jak loader, summary, translate, websearch, hybrid i innych. Tym razem jednak, odpowiedzialność za sposób posługiwania się narzędziami, w dużym stopniu przejdzie w ręce modelu, aczkolwiek dostępna logika nadal będzie miała dość liniowy charakter i nie daje zbyt wiele przestrzeni na 'kreatywność modelu'.</p><p>Poniżej widzimy wymianę wiadomości, w której poprosiłem o pobranie treści z trzech plików PDF zawierających faktury, wczytanie wskazanych informacji oraz przekazanie mi rezultatu w formie linku do pliku .csv.</p><img src="https://assets-v2.circle.so/bhu1eotlt1prg39euo894edmbzac" style="width: 100%;"><p>Nietrudno się domyślić, że takie polecenia można przesyłać automatycznie, np. z odnośnikami do załączników maili oznaczonych wybraną etykietą. Źródłem danych mogłyby być także zdjęcia z naszego telefonu czy pliki wgrane na Dropbox.</p><p>Na tym jednak nie koniec, ponieważ różne kombinacje doboru narzędzi pozwalają na przesłanie <strong>długiego pliku</strong> z prośbą o przetłumaczenie z zachowaniem pełnego formatowania. Jak widać, tłumaczenie zostało przeprowadzone poprawnie, pomimo przekroczenia limitu "output tokens".</p><img src="https://assets-v2.circle.so/l08ncwtsejbbzkliogmt0o76igc5" style="width: 100%;"><p>No i ostatecznie mamy także możliwość pobierania wybranych treści stron www, co również może być wykonywane przez skrypty i automatyzacje działające dla nas w tle.</p><img src="https://assets-v2.circle.so/bb9uwynb3aluhztlvtlzp84vftxv" style="width: 100%;"><p>Logika przykładu polega więc na tym, aby:</p><ul><li><p>Zrozumieć zapytanie użytkownika i ułożyć na jego podstawie plan</p></li><li><p>Wykonać poszczególne kroki, z możliwością przekazywania kontekstu pomiędzy nimi. Zatem jeśli pierwszym krokiem jest 'przeglądanie Internetu', to jego rezultat będzie dostępny w dalszych etapach</p></li><li><p>Wśród dostępnych akcji znajduje się także opcja wgrania pliku na serwer i wygenerowania dla niego bezpośredniego linku</p></li><li><p>Po wykonaniu wszystkich kroków, model generuje ostateczną odpowiedź.</p></li></ul><p>Całość nie jest jednak gotowa na każdy z możliwych scenariuszy i w założeniu ma działać dla powtarzalnych zadań takich jak wspomniane przetwarzanie dokumentów czy cykliczne pobieranie informacji z Internetu.</p><p><strong>WAŻNE:</strong> Logika przykładu web potrafi obsługiwać następujące sytuacje:</p><ul><li><p>Wczytaj link_do_pliku i przetłumacz z polskiego na angielski i podrzuć mi link do gotowego dokumentu</p></li><li><p>Pobierz wpisy na temat AI z https://news.ycombinator.com/newest</p></li><li><p>Podsumuj ten dokument: link</p></li><li><p>Wejdź na blog i pobierz artykuły z dziś (o ile jakieś są)</p></li><li><p>Wejdź na blog, pobierz artykuły z dziś (o ile jakieś są) i je dla mnie podsumuj</p></li></ul><p>Mówimy więc tutaj o prostych wiadomościach, które mogą uwzględniać przetwarzanie kilku źródeł oraz przekazywanie informacji pomiędzy etapami.</p><h2>Upload i tworzenie plików</h2><p>Modele językowe nie mają większych problemów z generowaniem treści dla dokumentów tekstowych. Markdown, JSON czy CSV mogą być także programistycznie przekonwertowane na formaty binarne, takie jak PDF, docx czy xlsx. Natomiast samo umieszczenie pliku na dysku, a także wygenerowanie linku do niego, musi mieć formę narzędzia.</p><p>W praktyce będziemy potrzebowali dwóch sposobów tworzenia plików. Jeden będzie dostępny dla użytkownika, a drugi dla LLM. Z tego powodu, w przykładzie web utworzyłem endpoint /api/upload. Co prawda nie będziemy z niego teraz korzystać, ale warto zwrócić w nim uwagę na kilka rzeczy:</p><ul><li><p>Plik jest <strong>wczytywany jako dokument</strong> i zapisywany w bazie danych</p></li><li><p>Do metadanych pliku dołączany jest identyfikator konwersacji</p></li><li><p>W odpowiedzi zwracane są informacje na temat pliku, łącznie z adresem URL, którym może posługiwać się LLM.</p></li></ul><img src="https://assets-v2.circle.so/3yjvexzfg9aah9x49h57h4fnuq5r" style="width: 100%;"><p><strong>Ważne:</strong> w przypadku produkcyjnych implementacji takich rozwiązań, należy upewnić się, że:</p><ul><li><p>Sprawdzamy mimeType wgrywanego pliku i odrzucamy te, które nie są zgodne z wspieranymi formatami</p></li><li><p>Poza typem pliku, powinniśmy sprawdzić także jego rozmiar</p></li><li><p>Link kierujący do pliku powinien wymagać uwierzytelnienia, np. klucza API bądź aktywnej sesji użytkownika</p></li></ul><p>Taki endpoint pozwala nam na przesyłanie plików do aplikacji i wykorzystywanie ich później w trakcie konwersacji na podstawie conversation_uuid.</p><p>Tworzenie pliku z pomocą LLM jest bardziej złożone, ponieważ musimy uwzględnić także <strong>napisanie treści</strong>. W przypadku przykładu web, model może zapisywać pliki, których zawartość jest wpisana przez niego "ręcznie". Może się jednak zdarzyć, że zapisanym plikiem będzie musiało być <strong>wcześniej wygenerowane tłumaczenie</strong>. W takim przypadku chcemy <strong>uniknąć ponownego przepisywania dokumentu</strong>, zwłaszcza że ze względu na limit okna tokenów wyjściowych (output tokens) możemy nie mieć takiej możliwości. Stosuję więc w nim znany już 'trick' z [[uuid]], wskazujący na dokumenty znajdujące się w kontekście, które podmieniane są na właściwą treść.</p><img src="https://assets-v2.circle.so/rqtykantyv7b5pputykih6knfhdw" style="width: 100%;"><p>Dokładnie ta sama możliwość funkcjonuje w odpowiedziach przesyłanych użytkownikowi. Na obrazku poniżej widzimy fragment promptu systemowego, który zawiera sekcję documents, a w niej wpis z treścią wcześniejszej wypowiedzi w postaci listy narzędzi.</p><img src="https://assets-v2.circle.so/b7s4s96arbipp365x5kh4str5cr6" style="width: 100%;"><p>Po stronie front-endu widzimy <strong>dokładnie tę samą treść</strong>, która w oryginale brzmiała: "Here is the extracted list of hardware\n\n[[ff7a079b-6299-4833-bf75-5e2c6fe57fba]]", natomiast placeholder został programistycznie podmieniony na wczytany wcześniej dokument.</p><img src="https://assets-v2.circle.so/hipimxhu5wrpsjzzeaplucyup4u2" style="width: 100%;"><p>Zatem tworzenie plików w przypadku LLM polega tutaj wyłącznie na wygenerowaniu nazwy oraz wskazania identyfikatorów, które mają zostać wczytane jako treść. Opcjonalnie model ma prawo uwzględnić dodatkowe formatowanie tej treści i własne komentarze.</p><h2>Planowanie</h2><p>Posługiwanie się narzędziami przez LLM stanowi połączenie dwóch elementów: programistycznego interfejsu oraz promptów. Sama logika może mieć charakter bardziej liniowy, który do tej pory już wiele razy widzieliśmy, albo charakter agencyjny, zdolny do wychodzenia poza ustalony schemat i rozwiązywania problemów z kategorii "open-ended".</p><p>Tym razem interesuje nas ten "środkowy" scenariusz, w którym model wyposażony w serię narzędzi ma możliwość korzystania z nich w dowolnej kolejności oraz ilości kroków. Nie może jednak zmienić raz ustalonego planu oraz wracać do wcześniejszych etapów. Poza tym sam system nie jest odporny na 'nieprzewidziane' scenariusze, więc polecenia użytkownika powinny być precyzyjne. Z tego powodu nie sprawdzi się on nam w takiej formie produkcyjnie, ale może pracować 'w tle' i zapisywać efekty swojej pracy w bazie danych lub przesyłać je na maila.</p><img src="https://assets-v2.circle.so/09cf4l1114t9s147dlqug2hv0jv1" style="width: 100%;"><p>Takie ograniczenie rodzi naturalny problem <strong>ograniczonej wiedzy początkowej</strong>. Nie możemy zatem od razu wygenerować wszystkich parametrów potrzebnych do uruchomienia niezbędnych narzędzi. W zamian możemy ustalić listę kroków oraz zapisać przy nich notatki lub zapytania, które mają charakter poleceń, jakie model generuje 'samemu sobie'. Jedynym warunkiem jest tutaj zachowanie kolejności działań.</p><p>Z lekcji S04E01 — Interfejs wiemy, że narzędzia muszą mieć unikatowe nazwy oraz instrukcję obsługi. Teraz przekonujemy się, że nie zawsze będzie to oczywiste, ponieważ mogą mieć różną złożoność i podkategorie. Na przykład file_process, odpowiedzialne za przetwarzanie dokumentów, ma obecnie 5 różnych typów. Ich opisy nie są potrzebne na początkowym etapie planowania, lecz dopiero w chwili, gdy dany typ zostanie wybrany.</p><img src="https://assets-v2.circle.so/1vr5mokhtso8t471t9sxzm09p2g3" style="width: 100%;"><p>Do czasu gdy LLM nie będą dysponowały większą zdolnością do zachowania uwagi (być może dzięki <a href="https://www.microsoft.com/en-us/research/publication/differential-transformer/" target="_blank" rel="noopener noreferrer">Differential Transformer</a>), proces planowania i podejmowania działań musi być podzielony na małe, wyspecjalizowane prompty. Trudność polega tylko na tym, aby na danym etapie dostarczyć wszystkie dane potrzebne do podjęcia dalszych działań, bez dodawania zbędnego 'szumu'.</p><h2>Podstawy kontekstu konwersacji</h2><p>Przykład web zapisuje wszystkie treści w bazie danych, w formie dokumentów, które omawialiśmy w lekcji S03E01. Każdy z wpisów łączony jest z bieżącą konwersacją oraz opcjonalnie może być dodany do silników wyszukiwania. Pozwala nam to nie tylko na późniejsze wykorzystanie tych dokumentów jako kontekst, ale także umożliwia elastyczne posługiwanie się nimi w ramach bieżącej interakcji.</p><p>Poniżej widzimy jeden z takich rekordów, którego główna treść to jedynie cena produktu wczytana z faktury. Natomiast w metadanych znajduje się informacja nadająca <strong>kontekst</strong> mówiący o tym, czym dokładnie są te liczby i skąd pochodzą.</p><img src="https://assets-v2.circle.so/6kgvofaaimoctkefonj0a1t2526l" style="width: 100%;"><p>Informacje zapisane w ten sposób mogą zostać w każdej chwili przywołane do kontekstu promptu systemowego wraz z informacją o tym skąd pochodzą oraz gdzie możemy się dowiedzieć więcej na ich temat.</p><p>Dokładnie w ten sposób będziemy zapisywać dane pochodzące z zewnętrznych źródeł, a następnie wczytywać je do konwersacji w formie "stanu", czyli obiektu stanowiącego "pamięć krótkoterminową" modelu. W przypadku jednego z moich projektów, stan uwzględnia:</p><ul><li><p><strong>kontekst</strong> (dostępne umiejętności, informacje z otoczenia, listę podjętych akcji, wczytanych dokumentów, podsumowania rozmowy, omawiane słowa kluczowe czy wczytane wspomnienia),</p></li><li><p><strong>informacje związane z rozumowaniem</strong> (aktualny status, dostępne kroki, aktualny plan działań, refleksja na jego temat oraz aktywne narzędzie)</p></li><li><p><strong>informacje na temat konwersacji</strong>: identyfikator interakcji (na potrzeby LangFuse), identyfikator rozmowy, listę wiadomości oraz związane z nią ustawienia</p></li></ul><img src="https://assets-v2.circle.so/f117iadqjuxw1b98u17ar9h78x81" style="width: 100%;"><p>Inaczej mówiąc, myśląc o kontekście konwersacji, będziemy mieć na myśli połączenie trzech rzeczy: <strong>wiedzy z bieżącej interakcji</strong>, <strong>wiedzy z pamięci długoterminowej</strong> oraz <strong>zmienne kontrolujące logikę po stronie programistycznej</strong>.</p><p>Kontekst konwersacji stanowi kluczowy element systemów agencyjnych, ponieważ pozwala na wykonywanie bardziej złożonych zadań. Nawet nasz przykład web pomimo ograniczeń wynikających z jego założeń, jest w stanie posługiwać się prostym kontekstem pozwalającym na przekazywanie informacji pomiędzy poszczególnymi etapami.</p><p>Poniżej widzimy, że użytkownik nie dostarczył treści artykułu w postaci adresu URL, lecz jedynie wskazał miejsce z którego ma zostać ona pobrana.</p><img src="https://assets-v2.circle.so/co6p1xytjbluqg0yqqm78yeta82v" style="width: 100%;"><p>Asystent poprawnie rozłożył to zadanie na mniejsze kroki i poprawnie posługiwał się dostępnym kontekstem, przekazując go między etapami.</p><img src="https://assets-v2.circle.so/6dy9bq4gmddxghnm08dye4z3feuk" style="width: 100%;"><h2>Podsumowanie</h2><p>Logika przeglądania stron www w przykładzie web opiera się o <strong>wygenerowanie listy zapytań do wyszukiwarki</strong> oraz <strong>decyzji o tym, których stron zawartość należy pobrać</strong>. Ewentualnie proces ten może być skrócony do jedynie pobrania treści wskazanego adresu URL.</p><p>Istnieją jednak narzędzia takie jak Code Interpreter (np. e2b), <a href="https://www.browserbase.com/" target="_blank" rel="noopener noreferrer">BrowserBase</a> czy zapewne znany Ci <a href="https://playwright.dev/" target="_blank" rel="noopener noreferrer">Playwright</a> lub <a href="https://pptr.dev/" target="_blank" rel="noopener noreferrer">Puppeteer</a>. Konkretnie mówimy tutaj o automatyzacji polegającej na uruchamianiu generowanego kodu, a także połączeniu możliwości rozumienia tekstu i obrazu na potrzeby podejmowania dynamicznych działań.</p><p>Choć w sieci pojawiają się przykłady pokazujące możliwości autonomicznego research'u i przeglądania Internetu w celu gromadzenia informacji, <strong>trudno obecnie mówić o wysokiej skuteczności bez narzucenia ograniczeń.</strong> Nawet sam web scraping nie pozwala na swobodne przeglądanie dowolnych stron i powinien być skonfigurowany pod dostęp do wybranych adresów lub opierać się o zewnętrzne rozwiązania takie jak <a href="https://apify.com/" target="_blank" rel="noopener noreferrer">apify</a>.</p><p>Przykład web pokazuje nam, że LLM wyposażony w narzędzia oraz mechanikę budowania i posługiwania się kontekstem, może wykonywać samodzielnie złożone zadania bez udziału człowieka. Jednak warunkiem koniecznym (przynajmniej na ten moment) jest precyzyjne określenie tego, co jest dla modelu dostępne, a co nie. W przeciwnym razie szybko pojawiają się problemy albo dotyczące możliwości samego modelu, albo barier wynikających z samej technologii (np. konieczności logowania na stronie www).</p><hr><h2>NOTATKA ZYGFRYDA</h2><img src="https://assets-v2.circle.so/4ujehy6scz1cqgnqmdx0d462qzz7" style="width: 50%;"><hr><h2>ZADANIE</h2><div class="embed"><iframe class="embedly-embed" src="//cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F1031639537%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F1031639537&amp;image=https%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1952755667-25590619d92cb78a4c49387b2e7a0b37d363f1c6ffa60cc1ee91deef0ca15f58-d_1280&amp;type=text%2Fhtml&amp;schema=vimeo" width="1920" height="1080" scrolling="no" title="Vimeo embed" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"></iframe></div><p>Zadanie: Wiemy już, że oprogramowanie do fabryk i magazynów robotów realizuje firma SoftoAI. Firm tego typu jest znacznie więcej. Centrala poprosiła Cię numerze piąty o przygotowanie uniwersalnego mechanizmu do poszukiwania informacji na takich stronach. Aby sprawdzić, czy Twój mechanizm działa zgodnie z oczekiwaniami, odpowiedz proszę na pytania centrali:</p><p><a href="https://centrala.ag3nts.org/data/TUTAJ-KLUCZ/softo.json" target="_blank" rel="noopener noreferrer">https://centrala.ag3nts.org/data/TUTAJ-KLUCZ/softo.json</a></p><p>Wszystkie informacje znajdziesz na stronie firmy SoftoAI:</p><p><a href="https://softo.ag3nts.org/" target="_blank" rel="noopener noreferrer">https://softo.ag3nts.org</a></p><p>Odpowiedzi wyślij do <strong>/report</strong>, w polu ‘answer’, w takiej samej formie, w jakiej centrala udostępniła pytania. Nazwa zadania to <strong>softo.</strong></p><p>Oczekiwany format odpowiedzi:</p><pre><code>{
    "01": "zwięzła i konkretna odpowiedź na pierwsze pytanie",
    "02": "zwięzła i konkretna odpowiedź na drugie pytanie",
    "03": "zwięzła i konkretna odpowiedź na trzecie pytanie"
}
</code></pre><p><br></p><p><strong>Co należy zrobić w zadaniu?</strong></p><ol start="1"><li><p>Pobierz listę pytań przesłanych od centrali z adresu: <a href="https://centrala.ag3nts.org/data/TUTAJ-KLUCZ/softo.json" target="_blank" rel="noopener noreferrer">https://centrala.ag3nts.org/data/TUTAJ-KLUCZ/softo.json</a></p></li><li><p>Pytania są trzy i mają one swoje numery: 01, 02 oraz 03. Z takimi samymi numerami musimy otrzymać odpowiedzi. Pytania się nie zmieniają.</p></li><li><p>Napisz automat, który wejdzie na stronę <a href="https://softo.ag3nts.org/" target="_blank" rel="noopener noreferrer">https://softo.ag3nts.org</a> i na podstawie pytań centrali zdecyduje, na którą podstronę serwisu należy się udać, po czym otworzy ją</p></li><li><p>Jeśli na stronie docelowej znajduje się odpowiedź na pytanie otrzymane od centrali, zapamiętaj ją i przejdź do opracowywania odpowiedzi na kolejne pytanie.</p></li><li><p>Jeśli na podstronie nie ma odpowiedzi, to zastanów się, czy znajdują się tam jakieś linki mogące doprowadzić Cię do znalezienia odpowiedzi.</p></li><li><p>Niektóre z pytań wymagają wejścia w głąb na 2-3 strony. Nie wszystkie pytania posiadają odpowiedź dostępną po jednym kliknięciu.</p></li><li><p>Gotowe odpowiedzi wyślij do zadania o nazwie <strong>softo</strong></p></li></ol><p><br></p><p>Zadanie da się rozwiązać bez problemu ‘ręcznie’, ale jeśli zadanie to ma mieć wpływ na Twój rozwój w dziedzinie LLM-ów i ich integracji z systemami IT, spróbuj je w pełni zautomatyzować.</p><p><br></p><p><strong>UWAGA</strong>: 🚨 bardzo odradzamy próbę zaindeksowania całego serwisu lub wrzucenia wszystkich podstron do kontekstu LLM-a. Przepali Ci to OGROMNE ilości tokenów i może słono kosztować. Serwis celowo został zaprojektowany w taki sposób, że niektóre z linków prowadzą do pułapek, a niektóre linki stanowią pętlę nieskończoną (strona A linkuje do strony B, ona do C, a ta znów do A itd.). Jedyną sensowną metodą na rozwiązanie tego zadania jest podejmowanie przez LLM-a świadomych decyzji, w co kliknąć.</p><p>Spoiler związany z optymalizacją kodu [zdekoduj base64]:</p><pre><code>MS4gWmFwYW1pxJl0dWogdyBkb3dvbG5laiBmb3JtaWUgbGlua2kganXFvMKgb2R3aWVkem9uZSwgYWJ5IHVuaWtuxIXEhyB6YXDEmXRsZW5pYSBtZWNoYW5pem11CjIuIE5hIHN0cm9uaWUgbW9nxIXCoHBvamF3acSHwqBzacSZwqAyLTMgbGlua2ksIGt0w7NyZSBwb3RlbmNqYWxuaWUgd3lnbMSFZGFqxIUsIGpha2J5IG1vZ8WCeSB6YXdpZXJhxIfCoHdhcnRvxZtjaW93ZSBkYW5lLiBOaWUgd2Nob2TFuiB3IGthxbxkeSB6IG5pY2gsIGEgamVkeW5pZSB3IHRlbiBuYWpiYXJkemllaiBwcmF3ZG9wb2RvYm55LgozLiBNb8W8ZXN6IChhbGUgbmllIG11c2lzeiEpIHNwb3J6xIVkemnEh8KgbWFwxJkgb2R3aWVkem9ueWNoIHN0cm9uIGkgaWNoIHphd2FydG/Fm2NpLiBTenVrYWrEhWMgb2Rwb3dpZWR6aSBuYSBweXRhbmllIG5yIDAxLCBwcmF3ZG9wb2RvYm5pZSBvZHdpZWR6aXN6IGtpbGthIHN0cm9uLiBDenkgc3p1a2FqxIVjIG9kcG93aWVkemkgbmEgcHl0YW5pZSAwMiBpIDAzIG5hcHJhd2TEmcKgbXVzaXN6IG9kd2llZHphxIcgamUgcG9ub3duaWUgaSB6bsOzdyB3eXN5xYJhxIcgaWNoIHRyZcWbxIfCoGRvIExMTS1hPw==</code></pre></div>
</body>
</html>